# 토픽 모델링(topic modeling)

## [토픽 모델링이란](https://wikidocs.net/30707)

## 필요 설치
아나콘다 프롬프트에서 
```
pip install -U gensim
```

## 사례 
[소수자 토픽모델링 프로젝트](https://github.com/FifthSaint/NewsTextMining201903)


## 실습

```python
import os
import pandas as pd

os.getcwd()
Path='C:\\Users\\hannews\\Documents\\외부활동\\2019 언론재단 데이터저널리즘 멘토링'
os.chdir(Path)
```

### 데이터 읽기


```python
from openpyxl import load_workbook
from collections import defaultdict
Theme="gay"
RawFile='data\\complete_gay.xlsx'
wb = load_workbook(RawFile)
ws = wb.active

# 키워드(칼럼 O)의 단어들 리스트로 읽기
words = ws['O']
words_list = [x.value.split(',') for x in words[1:]]

# 한번만 나타난 단어는 제거
frequency = defaultdict(int)
for text in words_list:
    for token in text:
        frequency[token] += 1
words_list = [[token for token in text if frequency[token] > 1] for text in words_list]
```

### 토픽 모델 만들기


```python
import logging
logging.basicConfig(format = '%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)

from gensim import corpora
from gensim.models import LdaModel
```


```python
K = 25 # the optimized number of the topics: gay 25
iterations = 1000 # 반복 횟수
random_state = 1 # 설정
fname="lda_"+Theme+"K"+str(K)+"R"+str(random_state)+"I"+str(iterations)


dictionary = corpora.Dictionary(words_list)
dictionary.save(fname+'_dictionary.pkl')

corpus = [dictionary.doc2bow(text) for text in words_list]
corpora.MmCorpus.serialize(fname+'_corpus.mm', corpus)

lda = LdaModel(corpus, 
               num_topics=K, 
               id2word=dictionary,
               random_state=random_state, 
               iterations=iterations)
lda.save(fname)
```

### 결과 보기 및 저장


```python
lda.print_topics(-1,20)

```


```python
topics = lda.print_topics(-1,20)
feat_fname = fname+'_feats.txt'
with open(feat_fname, 'w') as text_file:
    for topic_num, features in topics:
        text_file.write("Topic={0} \n {1} \n".format(topic_num, features))
```


```python

```
