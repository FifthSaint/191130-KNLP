# 텍스트의 기초통계

```python
import nltk
nltk.download()
```


```python
from nltk.book import *
```


```python
type(text1)
```


```python
text1.concordance("monstrous")
```


```python
text1.similar("monstrous")
```


```python
text2.similar("monstrous")
```


```python
text2.common_contexts(["monstrous", "very"])
```


```python
import matplotlib
text4.dispersion_plot(["citizens", "democracy", "freedom", "duties", "Amercia"])
```


```python
text3.generate()
```


```python
len(text3)
```


```python
sorted(set(text3))
```


```python
len(set(text3))
```


```python
len(set(text3)) / len(text3)
```

특정 단어에 집중해서 몇 개가 나왔는지, 전체 단어 중에서 비율은 얼마나 되는지 등을 계산


```python
text3.count("smote")
100 * text4.count('a') / len(text4)
```


```python
def lexical_diversity(text):
    return len(set(text)) / len(text)

def percentage(count, total):
    return 100 * count / total
```


```python
lexical_diversity(text3)
```


```python
lexical_diversity(text5)
```


```python
percentage(4,5)
percentage(text4.count('a'), len(text4))
```


```python
from konlpy.corpus import kolaw
```


```python
fids = kolaw.fileids()
fobj = kolaw.open(fids[0])
print(fobj.read(150))
kotext = fobj.read()
```


```python
len(kotext)
```


```python
sorted(set(kotext))
```


```python
len(set(kotext))
```

단어별로 추출하지 못하고 '문자'별로 추출하기 때문


```python
from konlpy.tag import Okt
okt=Okt()
print(okt.morphs(kotext))
```


```python
kotkn = okt.morphs(kotext)
len(kotkn)
```


```python
kotkn[:10]
sorted()
```
